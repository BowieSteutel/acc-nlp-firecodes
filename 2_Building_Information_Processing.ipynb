{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "mount_file_id": "1DAlPEsIYctHixPtC-jDTW5xYr7RQCMy9",
      "authorship_tag": "ABX9TyOZIfF4ObL2vBkmA1Zd5/pK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BowieSteutel/acc-nlp-firecodes/blob/main/2_Building_Information_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# **Module 2 - Building Information Processing**\n",
        "\n"
      ],
      "metadata": {
        "id": "dLp-pF81dzgJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "*This module uses the ontologies to convert the IFC use cases to RDF.*"
      ],
      "metadata": {
        "id": "HTpd6UGXfzbt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Prepare libraries**"
      ],
      "metadata": {
        "id": "GmvJdLqe0Szs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import standard libraries\n",
        "from collections import defaultdict # for empty dictionary entries\n",
        "from datetime import datetime # for determining the current time for the base URI"
      ],
      "metadata": {
        "id": "uGTkBJKvxTJP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# IfcOpenShell (for reading IFC files)\n",
        "!pip install ifcopenshell pandas requests owlrl --quiet\n",
        "import ifcopenshell as ios\n",
        "import ifcopenshell.guid\n",
        "import ifcopenshell.util\n",
        "import ifcopenshell.util.element\n",
        "import ifcopenshell.util.unit\n",
        "import ifcopenshell.util.pset"
      ],
      "metadata": {
        "id": "xmCjVcfy0BWN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# RDFLib (for RDF conversion)\n",
        "!pip install rdflib --quiet\n",
        "import rdflib\n",
        "from rdflib import Graph, Namespace, Literal, URIRef"
      ],
      "metadata": {
        "id": "_zTHlTV2iTqs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# pySHACL (for materialization)\n",
        "!pip install pyshacl --quiet\n",
        "import pyshacl"
      ],
      "metadata": {
        "id": "komz4FBTiLe4"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Prepare inputs & outputs**"
      ],
      "metadata": {
        "id": "CcQNcFjwNCg8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Change root directory (update after downloading)\n",
        "\n",
        "root_directory = \"/content/drive/MyDrive/FINAL_CODE_THESIS\" #  @param {\"type\":\"string\", \"placeholder\":\"\"}\n",
        "import sys\n",
        "from pathlib import Path\n",
        "if 'google.colab' in sys.modules:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive', force_remount=False)\n",
        "    %cd {root_directory}"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "rnsV4psd0yzN",
        "outputId": "786acebd-9c7b-4a90-ee29-506d51eb4a77"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "/content/drive/MyDrive/FINAL_CODE_THESIS\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Define filepaths\n",
        "# Use case models to convert & output name\n",
        "input_correct = \"input/use_case_correct.ifc\" # @param {type:\"string\", placeholder:\"(ifc)\"}\n",
        "output_correct = \"output/use_case_correct.ttl\"  # @param {type:\"string\", placeholder:\"(ttl)\"}\n",
        "input_incorrect = \"input/use_case_incorrect.ifc\" # @param {type:\"string\", placeholder:\"(ifc)\"}\n",
        "output_incorrect = \"output/use_case_incorrect.ttl\" # @param {type:\"string\", placeholder:\"(ttl)\"}\n",
        "\n",
        "# Ontologies (for materialization)\n",
        "ont_path_isolated = \"input/custom_ontology_isolated.ttl\" # @param {type:\"string\"}\n",
        "ont_path_alignment = \"input/ontology_alignment.ttl\" # @param {type:\"string\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "QzCQaNjxohWY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define namespaces"
      ],
      "metadata": {
        "id": "yQKIgUTThA_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load default namespaces\n",
        "from rdflib.namespace import RDF, RDFS, OWL, XSD\n",
        "\n",
        "# define other namespaces\n",
        "#DCE = \"https://purl.org/dc/elements/1.1/\"\n",
        "#VANN = \"https://purl.org/vocab/vann/\"\n",
        "#CC = \"https://creativecommons.org/ns#\"\n",
        "BOT = \"https://w3id.org/bot#\"\n",
        "BEO = \"https://w3id.org/beo#\"\n",
        "#BEO = \"https://pi.pauwel.be/voc/buildingelement#\"\n",
        "#MEP = \"https://pi.pauwel.be/voc/distributionelement#\"\n",
        "#GEOM = \"https://w3id.org/geom#\"\n",
        "PROPS = \"https://w3id.org/props#\"\n",
        "#QUDT = \"http://qudt.org/schema/qudt/\"\n",
        "QUDT = \"http://qudt.org/schema/shacl/qudt/\"\n",
        "UNIT = \"https://qudt.org/vocab/unit/\"\n",
        "PSET = \"https://example.org/pset#\"\n",
        "MAT = \"https://example.org/material#\"\n",
        "#IFC = \"https://standards.buildingsmart.org/IFC/DEV/IFC4_1/FINAL/\"\n",
        "# IFC = \"https://w3id.org/ifc/IFC4#\"\n",
        "IFC = \"https://w3id.org/ifc/IFC4X3_ADD2#\"\n",
        "EX = \"https://example.org/ns#\"\n",
        "#EMPTY = \"https://example.org/\"\n",
        "#SCHEMA = \"https://schema.org/\""
      ],
      "metadata": {
        "id": "A0bGipZR0gg8"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "# **Prepare file conversion functions**"
      ],
      "metadata": {
        "id": "rQpZaGgY0ULT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Headers"
      ],
      "metadata": {
        "id": "khsxXhSZVVum"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def RDF_header(title):\n",
        "  return f'''\n",
        "\n",
        "#################################################################\n",
        "#\\t{title}\n",
        "#################################################################\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "j2TC2JTCVjzc"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### cleanString"
      ],
      "metadata": {
        "id": "0tYLSLVh9CnG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# properties\n",
        "def cleanString(name):\n",
        "    name = ''.join(x for x in name.title() if not x.isspace())\n",
        "    name = name.replace('\\\\', '')\n",
        "    name = name.replace('/', '')\n",
        "    name = name.replace('(', '_')\n",
        "    name = name.replace(')', '')\n",
        "    # NEW DEFINITIONS FOR RDF SUPPORT:\n",
        "    name = name.replace(':', '_')\n",
        "    name = name.replace(';', '_')\n",
        "    name = name.replace('[', '_')\n",
        "    name = name.replace(']', '_')\n",
        "    name = name.replace('.', '_')\n",
        "    name = name.replace(',', '_')\n",
        "    return name"
      ],
      "metadata": {
        "id": "AIgS0imF0lRy"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load unit vocabulary from QUDT\n",
        "unit_vocab = Graph()\n",
        "# unit_vocab.parse(\"https://qudt.org/2.1/vocab/unit.ttl\", format=\"turtle\")  # This URL does not use qudt:scalingOf\n",
        "unit_vocab.parse(\"https://qudt.org/vocab/unit/\", format=\"turtle\")  # This URL uses qudt:scalingOf"
      ],
      "metadata": {
        "id": "qySf3IyZriOz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "87e3a42a-9ab9-49ad-a6ff-b5736a60804c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Graph identifier=N6e9802bdeae04968970c99afe24513cf (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### convert2QUDT"
      ],
      "metadata": {
        "id": "d94vIHy49ER8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Find labels in qudt\n",
        "\n",
        "def convert2QUDT(original_unit, ifc_unit, ifc_name):\n",
        "  ifc_unit = str(ifc_unit).lower() # make case-insensitive\n",
        "  ifc_unit = ifc_unit.replace(\"pound\", \"pound( MASS)?\") #make sure pounds are matched\n",
        "  #ifc_unit = ifc_unit.replace(\"meter\", \"metre\") #make sure meters (en-US) are matched as metres (en)\n",
        "  ifc_unit = ifc_unit.replace(\"_\", \" \") #make sure meters (en-US) are matched as metres (en)\n",
        "\n",
        "  query = \"\"\"\n",
        "  PREFIX rdfs: <http://www.w3.org/2000/01/rdf-schema#>\n",
        "  PREFIX unit: <\"\"\" + UNIT + \"\"\">\n",
        "\n",
        "  SELECT ?unitname ?factor\n",
        "  WHERE {\n",
        "    ?unitname rdfs:label ?label .\n",
        "    ?unitname qudt:conversionMultiplier ?factor .\n",
        "      FILTER regex(?label, \"^\"\"\" + ifc_unit + \"\"\"$\"@en, \"i\" )\n",
        "  }\"\"\"\n",
        "\n",
        "  #find matches\n",
        "  results = unit_vocab.query(query)\n",
        "\n",
        "  if not results:\n",
        "    return None\n",
        "\n",
        "\n",
        "  for row in results:\n",
        "    if not row.unitname:\n",
        "      continue  # Skip if unit is None\n",
        "    # Assign a value to qudt_unit before using it\n",
        "    qudt_unit = str(row.unitname)\n",
        "\n",
        "    #if row.unitname.startswith(\"<\"+str(UNIT)):  # Check if it's a QUDT unit\n",
        "    qudt_unit = \"unit:\"+qudt_unit.split('/')[-1]  # Return prefix format\n",
        "    #else:\n",
        "      #qudt_unit = f\"<{row.unitname}>\" # return as URI\n",
        "    # if (row.factor, 3) == 1:\n",
        "    #   factor =  int(1)\n",
        "    # else:\n",
        "    #   factor = row.factor\n",
        "    return qudt_unit#, factor\n",
        "print(convert2QUDT(None, None, \"Luminous Efficacy\"))\n",
        "print(convert2QUDT(\"dB\", None, \"SOUNDPOWER\"))\n",
        "print(convert2QUDT(None, \"Kilogram\", None))"
      ],
      "metadata": {
        "id": "bSnViGSke96S",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c89f8550-e194-4b2e-f172-0f84be3cd9fe"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "unit:KiloGM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### findUnits"
      ],
      "metadata": {
        "id": "FbEdYcTd9HxT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dict_exponents = {\n",
        "    \"None\": \"\",\n",
        "    None : \"\",\n",
        "    1 : \"\",\n",
        "    2 : \"Square(?:d)?\",\n",
        "    3 : \"Cub(?:ic|ed)\",\n",
        "    4 : \"Quartic\",\n",
        "    5 : \"Quintic\",\n",
        "    6 : \"Sextic\",\n",
        "}\n",
        "\n",
        "\n",
        "def cleanUnitName(unit):\n",
        "    unit_name = unit.replace(\"_\", \" \")\n",
        "    unit_name = unit_name.title()\n",
        "    unit_name = unit_name.replace(\"Meter\", \"Metre\")\n",
        "    #unit_name = unit_name.replace(\" Per \", \" per \")\n",
        "    #unit_name = unit_name.replace(\" Per \", \"(s?) per \")\n",
        "    unit_name += \"(s?)\"\n",
        "\n",
        "    return unit_name\n",
        "\n",
        "def findUnitName(unit):\n",
        "    name = str(unit.Name)\n",
        "    try:\n",
        "      prefix = unit.Prefix\n",
        "      if prefix != \"None\":\n",
        "          return cleanUnitName(prefix+name)\n",
        "      else:\n",
        "          return cleanUnitName(name)\n",
        "    except:\n",
        "        return cleanUnitName(name)\n",
        "\n",
        "\n",
        "def combineUnits(d_u):\n",
        "    #comb = \"\"\n",
        "    #print(len(d_u))\n",
        "    if len(d_u) == 0:\n",
        "        return \"\"\n",
        "    elif len(d_u) == 1:\n",
        "        return d_u[0]\n",
        "    elif len(d_u) == 2:\n",
        "        return f\"({d_u[0]} {d_u[1]}|{d_u[1]} {d_u[0]})\"\n",
        "    elif len(d_u) == 3:\n",
        "        return f\"({d_u[0]} {d_u[1]} {d_u[2]}|{d_u[0]} {d_u[2]} {d_u[1]}|{d_u[1]} {d_u[0]} {d_u[2]}|{d_u[1]} {d_u[2]} {d_u[0]}|{d_u[2]} {d_u[0]} {d_u[1]}|{d_u[2]} {d_u[1]} {d_u[0]})\"\n",
        "    else:\n",
        "        return \"ERROR\"\n",
        "        #comb = \" \".join([x for x in d_u])\n",
        "\n",
        "def standardizeMeasurements(unit, name, factor, from_unit, to_unit):\n",
        "    from_unit = \"\"\n",
        "    to_unit = \"\"\n",
        "    match unit.is_a():\n",
        "        case \"IfcSIUnit\":\n",
        "            from_unit_name = str(unit.Name)\n",
        "            try:\n",
        "                factor *= ios.util.unit.prefixes[unit.Prefix]\n",
        "                from_unit += cleanUnitName(str(unit.Prefix) + from_unit_name)\n",
        "            except:\n",
        "                from_unit += cleanUnitName(from_unit_name)\n",
        "            if unit.Name == \"GRAM\":\n",
        "                factor *= 0.001 #kilogram is only SI unit with prefix in the base unit\n",
        "                to_unit += cleanUnitName(\"Kilo\" + from_unit_name)\n",
        "            else:\n",
        "                to_unit += cleanUnitName(from_unit_name)\n",
        "        case \"IfcConversionBasedUnit\":\n",
        "            factor *= unit.ConversionFactor.ValueComponent[0]\n",
        "            from_unit += findUnitName(unit)\n",
        "            to_unit += findUnitName(unit.ConversionFactor.UnitComponent)\n",
        "\n",
        "        case \"IfcDerivedUnit\":\n",
        "            if unit.UserDefinedType:\n",
        "                name = unit.UserDefinedType\n",
        "                #print(name)\n",
        "            derived_num = []\n",
        "            derived_denom = []\n",
        "            derived_original = \"\"\n",
        "            for element in unit.Elements: #decompose derived units\n",
        "                element_name, element_factor, element_from_unit, element_to_unit = standardizeMeasurements(element, element.Unit, factor, \"\", \"\")\n",
        "                derived_original += element_from_unit + \" \"\n",
        "                factor *= element_factor**element.Exponent\n",
        "\n",
        "                # do the following:\n",
        "                # if factor - something: [unit 1](s)? per [unit2]\n",
        "                # if factor bigger than 1: square, cubic, quartic, quintic, sextic, heptic, octic\n",
        "                # meter = metre\n",
        "                # if multiple multiplied next to each other: both order should be tried, e.g.: N/Ks² and N/s²K\n",
        "                # also try exponent on both sides, e.g. square metre & metre squared, cubic metre & metre cubed\n",
        "                # no numerator? leave out\n",
        "                # no denominator? replace \"per\" with \"(?:Reciprocal |per )?\"\n",
        "\n",
        "                derived_exp = str(dict_exponents.get(abs(element.Exponent)))\n",
        "\n",
        "                derived_name = str(findUnitName(element_name))\n",
        "                if abs(element.Exponent) == 2:\n",
        "                    derived_element = f\"({derived_exp} {derived_name}|{derived_name} {derived_exp})\"\n",
        "                elif derived_exp != \"\":\n",
        "                    derived_element = f\"({derived_exp} {derived_name})\"\n",
        "                else:\n",
        "                    derived_element = derived_name\n",
        "\n",
        "                # add elements to numerator or denominator based on exponent\n",
        "                if abs(element.Exponent) == element.Exponent:\n",
        "                    derived_num.append(derived_element)\n",
        "                else:\n",
        "                    derived_denom.append(derived_element)\n",
        "            from_unit = derived_original\n",
        "            derived_num_comb = combineUnits(derived_num)\n",
        "            derived_denom_comb = combineUnits(derived_denom)\n",
        "            if not derived_num_comb and not derived_denom_comb:\n",
        "                to_unit = from_unit\n",
        "            if not derived_num_comb:\n",
        "                to_unit = \"(?:Reciprocal |per )?\"+derived_denom_comb\n",
        "            elif not derived_denom_comb:\n",
        "                to_unit = derived_num_comb\n",
        "            elif derived_num_comb and derived_denom_comb:\n",
        "                to_unit = f\"(?:{derived_num_comb} per {derived_denom_comb})\"\n",
        "            return name, factor, from_unit, to_unit\n",
        "\n",
        "    return name, factor, from_unit, to_unit\n",
        "\n",
        "def findUnits(model):\n",
        "    units = model.by_type(\"IfcUnitAssignment\")[0]\n",
        "    dict_units = dict()\n",
        "    for u in units.Units:\n",
        "        name, factor, from_unit, to_unit = standardizeMeasurements(u, u.UnitType[:-4], 1, \"\", \"\")\n",
        "        dict_units[name] = [factor, convert2QUDT(from_unit, to_unit, name)]\n",
        "        #print(name, factor, \"|\", from_unit, \"-->\", to_unit)\n",
        "    return dict_units\n",
        "\n",
        "\n",
        "#also check if user defined type, in that case just take that name. Do the same thing later with Ifc..Measure vs"
      ],
      "metadata": {
        "id": "Y1Ji5NeQbyz-"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### printProperties"
      ],
      "metadata": {
        "id": "o4if5NSH9YsU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def printValue(name, value, output, tab, unit):\n",
        "    output += tab*\"\\t\"+\"props:\"+name\n",
        "    if isinstance(value, bool):\n",
        "        output += \" \\\"\"+str(value) +\"\\\"^^xsd:boolean \"\n",
        "    elif isinstance(value, int):\n",
        "        # If measurement has a unit, make a blank property node. Else, skip this step\n",
        "        if unit:\n",
        "            output += \" [\\n\"+(tab+1)*\"\\t\"+\"qudt:NumericValue\"\n",
        "        output += \" \\\"\"+str(value) +\"\\\"^^xsd:int \"\n",
        "        if unit:\n",
        "            output += \";\\n\"+(tab+1)*\"\\t\"+\"qudt:hasUnit \"+str(unit)+\" ;\\n\"+tab*\"\\t\"+\"] \" #\" ;\"\n",
        "            #output += \"\\n\"+(tab+1)*\"\\t\"+\"] ; \"\n",
        "    elif isinstance(value, float):\n",
        "        # If measurement has a unit, make a blank property node. Else, skip this step\n",
        "        if unit:\n",
        "            output += \" [\\n\"+(tab+1)*\"\\t\"+\"qudt:NumericValue\"\n",
        "        output += \" \\\"\"+str(value) +\"\\\"^^xsd:double \"\n",
        "        if unit:\n",
        "            output += \";\\n\"+(tab+1)*\"\\t\"+\"qudt:hasUnit \"+str(unit)+\" ;\\n\"+tab*\"\\t\"+\"] \" #\" ;\"\n",
        "            #output += \"\\n\"+tab*\"\\t\"+\"] ; \"\n",
        "    else:\n",
        "        output += \" \\\"\"+str(value) +\"\\\"^^xsd:string \"\n",
        "    return output\n",
        "\n",
        "def printProperties(pset_name, properties, output, tab, model_units):\n",
        "    for prop_name, prop in properties.items():\n",
        "        if prop_name == \"id\":\n",
        "            continue\n",
        "\n",
        "        standard_unit = None\n",
        "\n",
        "        if type(prop) == dict:\n",
        "            if pset_name == \"BaseQuantities\": #QTO\n",
        "                prop_value = prop.get('value')\n",
        "                prop_unit = prop.get('class')\n",
        "                if prop_unit[:11] == \"IfcQuantity\":\n",
        "                    prop_standardized = model_units.get(prop_unit[11:].upper())\n",
        "                    prop_value *= prop_standardized[0]\n",
        "                    standard_unit = prop_standardized[1]\n",
        "            else: #PSET\n",
        "                prop_value = prop.get('value')\n",
        "                prop_unit = prop.get('value_type')\n",
        "                if prop_unit[-12:] == \"RatioMeasure\": #special case for ratios, which have no unit\n",
        "                    prop_value = prop_value\n",
        "                    standard_unit = \"unit:UNITLESS\"\n",
        "                elif prop_unit[-7:] == \"Measure\": #standardize measures\n",
        "                    try:\n",
        "                        prop_standardized = model_units.get(prop_unit[3:-7].upper())\n",
        "                        prop_value *= prop_standardized[0]\n",
        "                        standard_unit = prop_standardized[1]\n",
        "                    except:\n",
        "                        print(\"ERROR CONVERTING\", prop_unit, prop_value)\n",
        "\n",
        "        else:\n",
        "            prop_value = prop\n",
        "\n",
        "        prop_name = cleanString(prop_name)\n",
        "        output += \";\\n\"\n",
        "        #if qudt_unit:\n",
        "        output = printValue(prop_name, prop_value, output, tab+1, standard_unit)\n",
        "        #else:\n",
        "            #output = printValue(prop_name, prop_value, output, tab+1, None)\n",
        "    return output"
      ],
      "metadata": {
        "id": "PsLEOkSR4z4X"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writePropertySets"
      ],
      "metadata": {
        "id": "65ymm5Ya-Ucj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writePropertySets(instance_name, psets, output, model_units):\n",
        "    for name, properties in psets.items():\n",
        "        pset_name = cleanString(name)\n",
        "\n",
        "        # remove * from Pset_*Common for generalization purposes (original name still stored with rdfs:label)\n",
        "        if pset_name.lower().endswith(\"common\"):\n",
        "            pset_name = \"Common\"\n",
        "        output += \";\\n\"\n",
        "        output += f\"\\tpset:{pset_name} [\\n\"\n",
        "        output += f\"\\t\\trdfs:label \\\"{name}\\\"^^xsd:string \"# ;\\n\"\n",
        "\n",
        "        # for prop in properties:\n",
        "        #   output = printProperties(name, prop, output, 1)\n",
        "        output = printProperties(name, properties, output, 1, model_units)\n",
        "        output += \";\\n\\t] \"\n",
        "        #output += \"\\n\\t\\t] \"\n",
        "        # if output[-2:] == \"] \":\n",
        "        #   ...\n",
        "        # else:\n",
        "        #   #output += \"] \"\n",
        "    output += \". \\n\\n\"\n",
        "    return(output)\n"
      ],
      "metadata": {
        "id": "xgVpQrpJ2CpP"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### loadBEO & IFC2BEO"
      ],
      "metadata": {
        "id": "Mx4-IXHP-WJr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare BEO\n",
        "def loadBEO():\n",
        "    # Load BEO ontology\n",
        "    beo_file = \"https://cramonell.github.io/beo/actual/ontology.ttl\"\n",
        "\n",
        "    g_beo = Graph()\n",
        "    g_beo.parse(beo_file, format=\"turtle\")\n",
        "\n",
        "    # Extract all BEO classes\n",
        "    beo_classes = {\n",
        "        str(cls).split(\"#\")[-1]: cls for cls in g_beo.subjects(predicate=None, object=URIRef(\"http://www.w3.org/2002/07/owl#Class\"))\n",
        "    }\n",
        "\n",
        "    return beo_classes\n",
        "\n",
        "def IFC2BEO(ifc_name, beo_classes):\n",
        "    name = ifc_name.split('Ifc')[-1] # Remove \"(ifc:)Ifc\"\n",
        "    if name in beo_classes:\n",
        "        return \"beo:\"+beo_classes[name].split('#')[1]\n",
        "    else:\n",
        "        if \":\" in ifc_name: # if name already has a format, return it as is\n",
        "            return ifc_name\n",
        "        else:           # otherwise, return ifc:ifc_name\n",
        "            return \"ifc:\"+ifc_name"
      ],
      "metadata": {
        "id": "ChQg24G4Sz2_"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### findCompartments"
      ],
      "metadata": {
        "id": "AxyvOFQw-m6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# finding ids and types of compartments in model\n",
        "def findCompartments(model):\n",
        "    compartments = dict()\n",
        "    # find the name and code of each compartment\n",
        "    for c in model.by_type(\"IfcSpace\"):\n",
        "        if c.Name:\n",
        "            if \"fire\" in c.LongName.lower():\n",
        "                #l_compartments.append([c.Name, None, c.LongName, c.id()])\n",
        "                if \"protected sub\" in c.LongName.lower():\n",
        "                    compartments[c.Name] = ['ex:ProtectedSubFireCompartment', c.id()]\n",
        "                elif \"sub\" in c.LongName.lower():\n",
        "                    compartments[c.Name] = ['ex:SubFireCompartment', c.id()]\n",
        "                else:\n",
        "                    compartments[c.Name] = ['ex:FireCompartment', c.id()]\n",
        "\n",
        "\n",
        "    #sort compartments by name\n",
        "    compartments = dict(sorted(compartments.items()))\n",
        "    #l_compartments = sorted(l_compartments, key=lambda x: x[0])\n",
        "\n",
        "    return compartments"
      ],
      "metadata": {
        "id": "8_JgRwrfELT-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeSites"
      ],
      "metadata": {
        "id": "D_rulk3D-l1y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeSites(model, model_units):\n",
        "  output = \"\"\n",
        "  for s in model.by_type(\"IfcSite\"):\n",
        "    instance_name = f\"inst:Site_{str(s.id())}\"\n",
        "    output += instance_name + \"\\n\"\n",
        "    output += \"\\ta bot:Site ;\" + \"\\n\"\n",
        "    if(s.Name):\n",
        "        output += \"\\trdfs:label \\\"\"+s.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "    if(s.Description):\n",
        "        output += \"\\trdfs:comment \\\"\"+s.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "    # output += \"\\tprops:hasGuid \\\"\"+ ios.guid.expand(s.GlobalId) +\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "    output += \"\\tprops:hasCompressedGuid \\\"\"+ s.GlobalId +\"\\\"^^xsd:string \"\n",
        "    for reldec in s.IsDecomposedBy:\n",
        "        if reldec is not None:\n",
        "            for b in reldec.RelatedObjects:\n",
        "                output += \";\\n\"\n",
        "                output += \"\\tbot:hasBuilding inst:Building_\"+ str(b.id()) + \" \"\n",
        "\n",
        "\n",
        "    #psets = ios.util.element.get_psets(s)\n",
        "    psets = ios.util.element.get_psets(s, verbose=True)\n",
        "    output = writePropertySets(instance_name, psets, output, model_units)\n",
        "\n",
        "  return output"
      ],
      "metadata": {
        "id": "i68iZhgm-CeL"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeBuildings"
      ],
      "metadata": {
        "id": "teGzc9Qk-qfU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeBuildings(model, model_units, model_compartments):\n",
        "    output = \"\"\n",
        "    for b in model.by_type(\"IfcBuilding\"):\n",
        "        instance_name = f\"inst:Building_{str(b.id())}\"\n",
        "        output += instance_name + \"\\n\"\n",
        "        output += \"\\ta bot:Building ;\" + \"\\n\"\n",
        "        if(b.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+b.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        if(b.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+b.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        # output += \"\\tprops:hasGuid \\\"\"+ ios.guid.expand(b.GlobalId) +\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output += \"\\tprops:hasCompressedGuid \\\"\"+ b.GlobalId +\"\\\"^^xsd:string \"\n",
        "        for reldec in b.IsDecomposedBy:\n",
        "            if reldec is not None:\n",
        "                for st in reldec.RelatedObjects:\n",
        "                    output += \";\\n\"\n",
        "                    output += \"\\tbot:hasStorey inst:Storey_\"+ str(st.id()) + \" \"\n",
        "        #psets = ios.util.element.get_psets(b)\n",
        "        psets = ios.util.element.get_psets(b, verbose=True)\n",
        "        output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "oimR5ChX0qD4"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeStoreys"
      ],
      "metadata": {
        "id": "dIVR3ge4-sSI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeStoreys(model, model_units, model_compartments):\n",
        "    output = \"\"\n",
        "    for b in model.by_type(\"IfcBuildingStorey\"):\n",
        "        instance_name = f\"inst:Storey_{str(b.id())}\"\n",
        "        output += instance_name + \"\\n\"\n",
        "        output += \"\\ta bot:Storey ;\" + \"\\n\"\n",
        "        if(b.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+b.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        if(b.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+b.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output += \"\\tprops:hasCompressedGuid \\\"\"+ b.GlobalId +\"\\\"^^xsd:string \"\n",
        "        for reldec in b.IsDecomposedBy:\n",
        "            if reldec is not None:\n",
        "                for sp in reldec.RelatedObjects:\n",
        "                    # make distinction between space and compartment\n",
        "                    sp_id = sp.id()\n",
        "                    if sp_id in [x[1] for x in model_compartments.values()]:\n",
        "                        None\n",
        "                    if sp_id not in [x[1] for x in model_compartments.values()]:\n",
        "                        output += \";\\n\"\n",
        "                        output += \"\\tbot:hasSpace inst:Space_\"+ str(sp.id()) + \" \"\n",
        "        for relcontains in b.ContainsElements:\n",
        "            if relcontains is not None:\n",
        "                for el in relcontains.RelatedElements:\n",
        "                    el_type = el.is_a()\n",
        "                    output += \";\\n\"\n",
        "                    output += \"\\tbot:containsElement inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "\n",
        "        psets = ios.util.element.get_psets(b, verbose=True)\n",
        "        output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "yViJqNve0ujh"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeCompartments"
      ],
      "metadata": {
        "id": "Egz_qkmD-toy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeCompartments(model, model_units, model_compartments):\n",
        "    output = \"\"\n",
        "    # go through compartment list in order\n",
        "    for c_id in [x[1] for x in model_compartments.values()]:\n",
        "        c = model[c_id]\n",
        "        instance_name = f\"inst:Compartment_{str(c_id)}\"\n",
        "        output += instance_name + \"\\n\"\n",
        "        output += f\"\\ta {str(model_compartments[c.Name][0])} ;\\n\"\n",
        "        if(c.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+c.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        if(c.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+c.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output += \"\\tprops:hasCompressedGuid \\\"\"+ c.GlobalId +\"\\\"^^xsd:string \"\n",
        "        try:\n",
        "            parent_code = str('.'.join(str(c.Name).split('.')[:-1]))\n",
        "            if parent_code != c.Name:\n",
        "                output += f';\\n\\tex:partOfCompartment inst:Compartment_{str(model_compartments[parent_code][1])} '\n",
        "        except:\n",
        "            None\n",
        "\n",
        "        psets = ios.util.element.get_psets(c, verbose=True)\n",
        "        output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "e7QhvNshELT_"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeSpaces"
      ],
      "metadata": {
        "id": "r4CzvIOt-u1A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeSpaces(model, model_units, model_compartments):\n",
        "    output = \"\"\n",
        "    for s in model.by_type(\"IfcSpace\"):\n",
        "        if s.id() not in [x[1] for x in model_compartments.values()]: #filter out compartments\n",
        "            instance_name = f\"inst:Space_{str(s.id())}\"\n",
        "            output += instance_name + \"\\n\"\n",
        "            output += \"\\ta bot:Space ;\\n\"\n",
        "            if(s.Name):\n",
        "                output += \"\\trdfs:label \\\"\"+s.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "            if(s.Description):\n",
        "                output += \"\\trdfs:comment \\\"\"+s.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "            output += \"\\tprops:hasCompressedGuid \\\"\"+ s.GlobalId +\"\\\"^^xsd:string \"\n",
        "            try:\n",
        "                space_in_c = ios.util.element.get_psets(s, verbose=True)['Other']['LocatedInCompartment']['value']\n",
        "                output += f';\\n\\tex:locatedInCompartment inst:Compartment_{str(model_compartments[space_in_c][1])} '\n",
        "            except:\n",
        "                None\n",
        "            for relbounded in s.BoundedBy:\n",
        "                if relbounded is not None:\n",
        "                    el = relbounded.RelatedBuildingElement\n",
        "                    if el is not None:\n",
        "                        el_type = el.is_a()\n",
        "                        output += \";\\n\"\n",
        "                        output += \"\\tbot:adjacentElement inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "            for relcontains in s.ContainsElements:\n",
        "                if relcontains is not None:\n",
        "                    for el in relcontains.RelatedElements:\n",
        "                        output += \";\\n\"\n",
        "                        output += \"\\tbot:containsElement inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "\n",
        "            psets = ios.util.element.get_psets(s, verbose=True)\n",
        "            output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "mUkmT8OTESoR"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeElements"
      ],
      "metadata": {
        "id": "GOWhLSpv-wCn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_materials(element, model):\n",
        "    materials = set()\n",
        "\n",
        "    # Direct material assignment\n",
        "    material_relations = model.get_inverse(element)\n",
        "    for rel in material_relations:\n",
        "        if \"IfcRelAssociatesMaterial\" in rel.is_a():\n",
        "            material = rel.RelatingMaterial\n",
        "            if material:\n",
        "                materials.add(material)\n",
        "    if materials:\n",
        "        return list(materials)[0] # flatten set\n",
        "\n",
        "def writeElements(model, model_units, beo_classes):\n",
        "    output = \"\"\n",
        "    for b in model.by_type(\"IfcElement\"):\n",
        "        element_type = b.is_a()\n",
        "        element_type_clean = element_type.replace(\"Ifc\", \"\")  # Remove \"Ifc\" prefix for better readability\n",
        "        instance_name = f\"inst:{element_type_clean}_{b.id()}\"\n",
        "        output += instance_name + \"\\n\"\n",
        "        output += f\"\\ta bot:Element , {IFC2BEO(element_type, beo_classes)} ;\" + \"\\n\"\n",
        "\n",
        "        if(b.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+b.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        if(b.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+b.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output += \"\\tprops:hasCompressedGuid \\\"\"+ b.GlobalId +\"\\\"^^xsd:string \"\n",
        "\n",
        "        material = get_materials(b, model)\n",
        "        if material:\n",
        "            # If it's a simple IfcMaterial\n",
        "            if material.is_a() == \"IfcMaterial\":\n",
        "                output += f\";\\n\\tex:hasMaterial inst:Material_{material.id()} \"\n",
        "\n",
        "            # If it's a layered material set\n",
        "            elif material.is_a() == \"IfcMaterialLayerSetUsage\":\n",
        "                layer_set = material.ForLayerSet\n",
        "                if layer_set and hasattr(layer_set, \"MaterialLayers\"):\n",
        "                    for layer in layer_set.MaterialLayers:\n",
        "                        if layer.Material:\n",
        "                            output += f\";\\n\\tex:hasMaterial inst:Material_{layer.Material.id()} \"\n",
        "\n",
        "            # If it's a material constituent set\n",
        "            elif material.is_a() == \"IfcMaterialConstituentSet\":\n",
        "                if hasattr(material, \"MaterialConstituents\"):\n",
        "                    for constituent in material.MaterialConstituents:\n",
        "                        if constituent.Material:\n",
        "                            output += f\";\\n\\tex:hasMaterial inst:Material_{constituent.Material.id()} \"\n",
        "\n",
        "        for relvoids in b.HasOpenings:\n",
        "            if relvoids is not None:\n",
        "                el = relvoids.RelatedOpeningElement\n",
        "                for relfills in el.HasFillings:\n",
        "                    if relfills is not None:\n",
        "                        filler = relfills.RelatedBuildingElement\n",
        "                        el_type = el.is_a()\n",
        "                        output += \";\\n\"\n",
        "                        output += \"\\tbot:hasSubElement inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "\n",
        "        for relvoids in b.HasOpenings:\n",
        "            if relvoids is not None:\n",
        "                el = relvoids.RelatedOpeningElement\n",
        "                for relfills in el.HasFillings:\n",
        "                    if relfills is not None:\n",
        "                        filler = relfills.RelatedBuildingElement\n",
        "                        el_type = el.is_a()\n",
        "                        output += \";\\n\"\n",
        "                        output += \"\\tbot:hasSubElement inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "\n",
        "        psets = ios.util.element.get_psets(b, verbose=True)\n",
        "        output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "Lp6K98L303No"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeMaterials"
      ],
      "metadata": {
        "id": "3MaILkizN2Uk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeMaterials(model, model_units):\n",
        "    output = \"\"\n",
        "    for m in model.by_type(\"IfcMaterial\")[:]:\n",
        "        instance_name = f\"inst:Material_{m.id()}\"\n",
        "        output += instance_name + \"\\n\"\n",
        "        output += f\"\\ta ex:Material ;\" + \"\\n\"\n",
        "\n",
        "        if(m.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+m.Name+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        if(m.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+m.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output = output[:-2] # remove last ; (needs to be done because of missing GuID and previous coding conventions)\n",
        "        psets = ios.util.element.get_psets(m, verbose=True)\n",
        "\n",
        "        # then, write them to RDF\n",
        "        output = writePropertySets(instance_name, psets, output, model_units)\n",
        "    return output"
      ],
      "metadata": {
        "id": "ZBQEzFN7N4MZ"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeAdjacencies"
      ],
      "metadata": {
        "id": "UYWO5Zoe-yeL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeAdjacencies(model, model_compartments):\n",
        "    sp_el_adj = defaultdict(set) # Dictionary to map elements to spaces\n",
        "    # Group spaces by shared boundary elements\n",
        "    for boundary in model.by_type(\"IfcRelSpaceBoundary\"):\n",
        "        space = boundary.RelatingSpace\n",
        "        element = boundary.RelatedBuildingElement\n",
        "\n",
        "        if space and element and element.is_a() not in ['IfcSlab', 'IfcRoof']: #only look for horizontal adjacency\n",
        "            element_name = element.is_a().replace('ifc', '')\n",
        "            sp_el_adj[f\"inst:{element_name}_{element.id()}\"].add(space.id())\n",
        "\n",
        "    # Use shared elements to determine adjacency\n",
        "    sp_sp_adj = defaultdict(list) # Dictionary to store adjacency between spaces\n",
        "    for element_id, space_ids in sp_el_adj.items():\n",
        "        space_ids = list(space_ids)\n",
        "        for i in range(len(space_ids)):\n",
        "            for j in range(i + 1, len(space_ids)):\n",
        "                sp_sp_adj[space_ids[i]].append(space_ids[j])\n",
        "                sp_sp_adj[space_ids[j]].append(space_ids[i])\n",
        "\n",
        "    # Remove duplicates from list\n",
        "    sp_sp_adj = [(id, list(set(data))) for (id, data) in sp_sp_adj.items()]\n",
        "\n",
        "    # Write compartment-compartment adjacencies\n",
        "    # The difference in the space-compartment containment indicates the adjacency of compartments\n",
        "    # (since ex:adjacentCompartment is disjoint with ex:locatedInCompartment)\n",
        "\n",
        "    # find out which which compartment each space is in, including parent compartments\n",
        "    space_in_c = dict()\n",
        "    for s in model.by_type(\"IfcSpace\"):\n",
        "        if s.id() not in [x[1] for x in model_compartments.values()]:\n",
        "            # find the compartment containment property\n",
        "            space_id = s.id()\n",
        "            psets = ios.util.element.get_psets(s, verbose=True)\n",
        "            # Check if 'Other' and 'LocatedInCompartment' keys exist\n",
        "            if 'Other' in psets and 'LocatedInCompartment' in psets['Other']:\n",
        "                c_code = psets['Other']['LocatedInCompartment']['value']\n",
        "                c_id = model_compartments[c_code][1]\n",
        "\n",
        "                # save to dictionary\n",
        "                space_in_c[space_id] = [c_id]\n",
        "\n",
        "                # find parent compartments and add to dictionary\n",
        "                c_parent = c_code\n",
        "                while '.' in c_parent:\n",
        "                    c_parent = '.'.join(str(c_parent).split('.')[:-1])\n",
        "                    space_in_c[space_id].append(model_compartments[c_parent][1])\n",
        "            else:\n",
        "                # Handle the case where the keys are missing\n",
        "                print(f\"Warning: Space {s.id()} is missing 'LocatedInCompartment' property or it's not in property set 'Other'\")\n",
        "\n",
        "    # find out which spaces are in each compartment\n",
        "    spaces_per_c = defaultdict(list)\n",
        "    for c_id in [x[1] for x in model_compartments.values()]:\n",
        "        for s in space_in_c.items():\n",
        "            if c_id in s[1]:\n",
        "                spaces_per_c[c_id].append(s[0])\n",
        "\n",
        "    adj_spaces = defaultdict(list)\n",
        "    adj_compartments = defaultdict(list)\n",
        "    con_compartments = defaultdict(list)\n",
        "\n",
        "    # Function for flattening a nested list into a single list.\n",
        "    def flatten(l):\n",
        "      return [item for sublist in l for item in sublist]\n",
        "    # find adjacent spaces for each contained space and find their respective compartment(s)\n",
        "    for c in spaces_per_c:\n",
        "        for s in spaces_per_c[c]:\n",
        "            # get all adjacent spaces from the spaces in the compartment\n",
        "            adj_spaces[c].extend(dict(sp_sp_adj)[s])\n",
        "            # get the compartments the contained spaces are contained in\n",
        "            con_compartments[c].append(space_in_c[s])\n",
        "\n",
        "        #flatten the list of contained compartments\n",
        "        con_compartments[c] = list(set(flatten(con_compartments[c])))\n",
        "\n",
        "        # get the list of adjacent spaces by excluding spaces from list that are contained in current compartment (disjointment)\n",
        "        adj_spaces[c] = [x for x in set(adj_spaces[c]) if x not in set(spaces_per_c[c])]\n",
        "\n",
        "        # get the compartments the adjacent spaces are contained in\n",
        "        adj_compartments[c] = list(set(flatten([space_in_c.get(s, []) for s in adj_spaces[c]])))\n",
        "\n",
        "        # get the adjacent compartments by excluding compartments containing the spaces in the compartment from the list (disjointment)\n",
        "        adj_compartments[c] = [x for x in adj_compartments.get(c, []) if x not in set(con_compartments[c])]\n",
        "\n",
        "    # write compartment adjacency\n",
        "    output = \"\"\n",
        "    for c in adj_compartments.items():\n",
        "        if c[1]:\n",
        "            output += f\"\\ninst:Compartment_{str(c[0])}\"\n",
        "            first = True\n",
        "            for adj_c in c[1]:\n",
        "                if first:\n",
        "                    first = False\n",
        "                else:\n",
        "                    output += \" ;\"\n",
        "                output += \"\\n\\tex:adjacentCompartment inst:Compartment_\"+str(adj_c)\n",
        "            output += \" .\\n\"\n",
        "\n",
        "    # Write space-space adjacencies\n",
        "    for s in sp_sp_adj:\n",
        "        output += f\"\\ninst:Space_{str(s[0])}\"\n",
        "        first = True\n",
        "        for adj_s in s[1]:\n",
        "            if first:\n",
        "                first = False\n",
        "            else:\n",
        "                output += \" ;\"\n",
        "            output += \"\\n\\tbot:adjacentZone inst:Space_\"+str(adj_s)\n",
        "\n",
        "        output += \" .\\n\"\n",
        "\n",
        "    return(output)"
      ],
      "metadata": {
        "id": "gcCvfsFNNyii"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### writeInterfaces"
      ],
      "metadata": {
        "id": "ATy-nYln-04g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def writeInterfaces(model):\n",
        "    output = \"\"\n",
        "    for b in model.by_type(\"IfcRelSpaceBoundary\"):\n",
        "        output += \"inst:interface_\"+str(b.id()) + \"\\n\"\n",
        "        output += \"\\ta bot:Interface ;\" + \"\\n\"\n",
        "        if(b.Name):\n",
        "            output += \"\\trdfs:label \\\"\"+b.Name+\"\\\"^^xsd:string ;\\n\"\n",
        "        if(b.Description):\n",
        "            output += \"\\trdfs:comment \\\"\"+b.Description+\"\\\"^^xsd:string ;\" + \"\\n\"\n",
        "        output += \"\\tprops:hasCompressedGuid \\\"\"+ b.GlobalId +\"\\\"^^xsd:string \"\n",
        "\n",
        "        sp = b.RelatingSpace\n",
        "        el = b.RelatedBuildingElement\n",
        "        if sp is not None:\n",
        "            output += \";\\n\"\n",
        "            output += \"\\tbot:interfaceOf inst:Space_\"+ str(sp.id()) + \" \"\n",
        "        if el is not None:\n",
        "            el_type = el.is_a()\n",
        "            output += \";\\n\"\n",
        "            output += \"\\tbot:interfaceOf inst:\" + el_type.replace(\"Ifc\", \"\") + \"_\" + str(el.id()) + \" \"\n",
        "\n",
        "        output += \". \\n\\n\"\n",
        "    return output"
      ],
      "metadata": {
        "id": "XhjnEIJyVVXi"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Full conversion module"
      ],
      "metadata": {
        "id": "lqPhcehEXhvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def IFC2TTL(input_ifc, output_ttl):\n",
        "    # open file\n",
        "    outputfile = open(output_ttl, \"w\").close() #clear file\n",
        "    outputfile = open(output_ttl, \"a\") #add to file\n",
        "\n",
        "    # define base URI\n",
        "    now = datetime.now()\n",
        "    current_time = now.strftime('%Y%m%d_%H%M%S')\n",
        "    baseURI = \"https://linkedbuildingdata.net/ifc/resources\" + current_time + \"/\"\n",
        "    #print(\"baseURI : \" + baseURI)\n",
        "\n",
        "    # creating a string to write\n",
        "    output = \"# baseURI: \" + baseURI + \"\\n\"\n",
        "    output += f\"@prefix inst: <{baseURI}> .\\n\"\n",
        "    output += f\"@prefix rdf: <{RDF}> .\\n\"\n",
        "    output += f\"@prefix rdfs: <{RDFS}> .\\n\"\n",
        "    output += f\"@prefix xsd: <{XSD}> .\\n\"\n",
        "    #output += f\"@prefix owl: <{OWL}> .\\n\"\n",
        "\n",
        "    output += f\"@prefix ifc: <{IFC}> .\\n\"\n",
        "    output += f\"@prefix bot: <{BOT}> .\\n\"\n",
        "    output += f\"@prefix beo: <{BEO}> .\\n\"\n",
        "    output += f\"@prefix ex: <{EX}> .\\n\"\n",
        "    #output += f\"@prefix : <{EMPTY}> .\\n\"\n",
        "\n",
        "    #output += f\"@prefix mep: <{MEP}> .\\n\"\n",
        "    #output += f\"@prefix geom: <{GEOM}> .\\n\"\n",
        "    #output += f\"@prefix mat: <{MAT}> .\\n\"\n",
        "\n",
        "    output += f\"@prefix props: <{PROPS}> .\\n\"\n",
        "    output += \"@prefix pset: <\" + PSET + \"> .\\n\"\n",
        "\n",
        "    output += f\"@prefix qudt:  <{QUDT}> .\\n\"\n",
        "    output += f\"@prefix unit: <{UNIT}> .\\n\"\n",
        "\n",
        "    outputfile.write(output)\n",
        "\n",
        "    output = \"\"\n",
        "\n",
        "    # LOAD REQUIRED DATA\n",
        "    print(\"Loading required data...\")\n",
        "    model = ios.open(input_ifc)\n",
        "    beo_classes = loadBEO() # load BEO for type recognition\n",
        "    model_units = findUnits(model) # extract units for standardization\n",
        "    model_compartments = findCompartments(model) #extract names of compartments\n",
        "\n",
        "    # WRITE DATA\n",
        "    outputfile.write(RDF_header(\"SPATIAL ELEMENTS\"))\n",
        "    print(\"Writing spatial elements...\")\n",
        "    outputfile.write(writeSites(model, model_units))\n",
        "    outputfile.write(writeBuildings(model, model_units, model_compartments))\n",
        "    outputfile.write(writeStoreys(model, model_units, model_compartments))\n",
        "    outputfile.write(writeCompartments(model, model_units, model_compartments))\n",
        "    outputfile.write(writeSpaces(model, model_units, model_compartments))\n",
        "\n",
        "    outputfile.write(RDF_header(\"BUILDING ELEMENTS\"))\n",
        "    print(\"Writing building elements...\")\n",
        "    outputfile.write(writeElements(model, model_units, beo_classes))\n",
        "\n",
        "    outputfile.write(RDF_header(\"BUILDING MATERIALS\"))\n",
        "    print(\"Writing building materials...\")\n",
        "    outputfile.write(writeMaterials(model, model_units))\n",
        "\n",
        "    outputfile.write(RDF_header(\"ADJACENCIES\"))\n",
        "    print(\"Writing adjacencies...\")\n",
        "    outputfile.write(writeAdjacencies(model, model_compartments))\n",
        "\n",
        "    outputfile.write(RDF_header(\"INTERFACES\"))\n",
        "    print(\"Writing interfaces...\")\n",
        "    outputfile.write(writeInterfaces(model))\n",
        "    outputfile.close()\n",
        "\n",
        "    print(\"RDF export finished.\")"
      ],
      "metadata": {
        "id": "D0orhNAW2lWL"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Convert IFC file to TTL**"
      ],
      "metadata": {
        "id": "uLCT5eBu0bB4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# convert correct use case model\n",
        "IFC2TTL(input_correct, output_correct)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKohjAnrXK1I",
        "outputId": "22c611dc-91b8-4807-98d9-faf6b6adf6f9"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading required data...\n",
            "Writing spatial elements...\n",
            "ERROR CONVERTING IfcCountMeasure 2\n",
            "Writing building elements...\n",
            "Writing building materials...\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.167\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.035\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.025\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.15\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.54\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.018999999999999996\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.3\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.51\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.3\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.65\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.025\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.1\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.49999999999999994\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.20899999999999996\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 45.0\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.18\n",
            "Writing adjacencies...\n",
            "Writing interfaces...\n",
            "RDF export finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert incorrect use case model\n",
        "IFC2TTL(input_incorrect, output_incorrect)"
      ],
      "metadata": {
        "id": "3afHRX11fgY2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd4dd887-24dd-4bdd-8fd9-08653ba635cc"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading required data...\n",
            "Writing spatial elements...\n",
            "ERROR CONVERTING IfcCountMeasure 2\n",
            "Writing building elements...\n",
            "Writing building materials...\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.167\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.035\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.025\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.15\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.54\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.018999999999999996\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.3\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.51\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.3\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.65\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.025\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.1\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.49999999999999994\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 1.046\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.20899999999999996\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 45.0\n",
            "ERROR CONVERTING IfcThermalConductivityMeasure 0.18\n",
            "Writing adjacencies...\n",
            "Warning: Space 781 is missing 'LocatedInCompartment' property or it's not in property set 'Other'\n",
            "Warning: Space 902 is missing 'LocatedInCompartment' property or it's not in property set 'Other'\n",
            "Writing interfaces...\n",
            "RDF export finished.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "# **Full materialization**\n",
        "\n",
        "\n",
        "Using full materialization based on the ontologies so that inference only has to be done once"
      ],
      "metadata": {
        "id": "Kug-LKOxE-zW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load data graphs\n",
        "data_graph_correct = Graph()\n",
        "data_graph_correct.parse(output_correct, format=\"turtle\")\n",
        "data_graph_incorrect = Graph()\n",
        "data_graph_incorrect.parse(output_incorrect, format=\"turtle\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq4u4V5LJIR1",
        "outputId": "462a56e6-0d1e-4ace-bffc-4b48bb4faccf"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Graph identifier=N2b9e32abfb224733bd19e7871eb87c2d (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare ontologies for materialization\n",
        "ont_graph_isolated = Graph()\n",
        "ont_graph_isolated.parse(ont_path_isolated, format=\"turtle\")\n",
        "ont_graph_alignment = Graph()\n",
        "ont_graph_alignment.parse(ont_path_alignment, format=\"turtle\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "10TQOWrvHrOE",
        "outputId": "a94f5bc5-f658-42dc-c641-a258c64b9a0b"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Graph identifier=Nec028a4878314ef9979b2337a563c9d0 (<class 'rdflib.graph.Graph'>)>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Materialize inferences in-place\n",
        "data_graph_correct_materialized = data_graph_correct\n",
        "conforms, report_graph, report_text = pyshacl.validate(\n",
        "    data_graph_correct_materialized,\n",
        "    shacl_graph=None,        # no shapes needed for inference\n",
        "    ont_graph=ont_graph_isolated + ont_graph_alignment,\n",
        "    inference='owlrl',       # Apply RDFS or OWL-RL reasoning (or both)\n",
        "    inplace=True,            # mutate data_graph to include inferred triples\n",
        "    serialize_report_graph=False\n",
        ")\n",
        "\n",
        "# Materialize inferences in-place\n",
        "data_graph_incorrect_materialized = data_graph_incorrect\n",
        "conforms, report_graph, report_text = pyshacl.validate(\n",
        "    data_graph_incorrect_materialized,\n",
        "    shacl_graph=None,        # no shapes needed for inference\n",
        "    ont_graph=ont_graph_isolated + ont_graph_alignment,\n",
        "    inference='owlrl',       # Apply RDFS or OWL-RL reasoning (or both)\n",
        "    inplace=True,            # mutate data_graph to include inferred triples\n",
        "    serialize_report_graph=False\n",
        ")\n",
        "\n",
        "# Save the materialized graphs\n",
        "data_graph_correct_materialized.serialize(destination=output_correct.replace('.ttl', '_materialized.ttl'), format=\"turtle\")\n",
        "data_graph_incorrect_materialized.serialize(destination=output_incorrect.replace('.ttl', '_materialized.ttl'), format=\"turtle\")\n",
        "\n",
        "# Preview the materialized graphs\n",
        "print(data_graph_correct_materialized.serialize(format=\"turtle\")[800:1400])\n",
        "print(data_graph_incorrect_materialized.serialize(format=\"turtle\")[800:1400])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ccd7OSEfmuyX",
        "outputId": "71966901-2958-4310-8612-86ab36e33d7a"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t .\n",
            "\n",
            "rdf:HTML a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:HTML .\n",
            "\n",
            "rdf:PlainLiteral a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:PlainLiteral .\n",
            "\n",
            "rdf:XMLLiteral a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:XMLLiteral .\n",
            "\n",
            "rdf:langString a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:langString .\n",
            "\n",
            "rdf:type owl:sameAs rdf:type .\n",
            "\n",
            "rdfs:Literal a rdfs:Datatype ;\n",
            "    owl:sameAs rdfs:Literal .\n",
            "\n",
            "rdfs:comment a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs:comment .\n",
            "\n",
            "rdfs:domain owl:sameAs rdfs:domain .\n",
            "\n",
            "rdfs:isDefinedBy a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs:isDefinedBy .\n",
            "\n",
            "rdfs:label a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs\n",
            "t .\n",
            "\n",
            "rdf:HTML a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:HTML .\n",
            "\n",
            "rdf:PlainLiteral a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:PlainLiteral .\n",
            "\n",
            "rdf:XMLLiteral a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:XMLLiteral .\n",
            "\n",
            "rdf:langString a rdfs:Datatype ;\n",
            "    owl:sameAs rdf:langString .\n",
            "\n",
            "rdf:type owl:sameAs rdf:type .\n",
            "\n",
            "rdfs:Literal a rdfs:Datatype ;\n",
            "    owl:sameAs rdfs:Literal .\n",
            "\n",
            "rdfs:comment a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs:comment .\n",
            "\n",
            "rdfs:domain owl:sameAs rdfs:domain .\n",
            "\n",
            "rdfs:isDefinedBy a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs:isDefinedBy .\n",
            "\n",
            "rdfs:label a owl:AnnotationProperty ;\n",
            "    owl:sameAs rdfs\n"
          ]
        }
      ]
    }
  ]
}